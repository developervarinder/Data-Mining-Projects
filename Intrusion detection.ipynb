{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Intrusion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:  Connection Classification\n",
    "\n",
    "Kaggle challenge: https://www.kaggle.com/sampadab17/network-intrusion-detection?select=Train_data.csv\n",
    "\n",
    "### Problem description\n",
    "The dataset to be audited was provided which consists of a wide variety of intrusions simulated in a military network environment. It created an environment to acquire raw TCP/IP dump data for a network by simulating a typical US Air Force LAN. The LAN was focused like a real environment and blasted with multiple attacks.\n",
    "\n",
    "## Data\n",
    "A connection is a sequence of TCP packets starting and ending at some time duration between which data flows to and from a source IP address to a target IP address under some well-defined protocol. Also, each connection is labelled as either normal or as an attack with exactly one specific attack type. Each connection record consists of about 100 bytes.\n",
    "For each TCP/IP connection, 41 quantitative and qualitative features are obtained from normal and attack data (3 qualitative and 38 quantitative features) .The class variable has two categories:\n",
    "• Normal\n",
    "• Anomalous\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Problem Statement\n",
    "Discuss the problem setting and the first implcations of the given data set... \n",
    "* What assumptions can we make about the data?\n",
    "* What problems are we expecting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train data has almost even number of normal and anomalous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: First Data Analysis, Cleaning and Feature Extraction\n",
    "* Import the data to a Pandas DataFrame\n",
    "* Run first simple statistics and visualizations\n",
    "* Is there a need to clean the data? If yes, do so...\n",
    "* Can you use the raw data directly, or should you extract features? What features are suitable ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Train_data.csv' , encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('Test_data.csv' , encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of columns and type of each column \n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['protocol_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row',None)\n",
    "data_train['service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation - we have 53% - 47% of class lables.\n",
    "# we can simply visualiztion the data frame!\n",
    "data_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train dataset shape - \", data_train.shape)\n",
    "print(\"Train dataset shape -\", data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of dataframe\n",
    "\n",
    "Class = pd.DataFrame(data['class'])\n",
    "Class\n",
    "\n",
    "##plotting the normal and anomalous records\n",
    "\n",
    "bins_colors = [\"yello\",\"red\"]\n",
    "sns.countplot('class', bins_colors=bins_colors, palette = bins_colors)\n",
    "\n",
    "plt.title(\"Class distribution\", fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no outliers\n",
    "data.boxplot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "#extract numerical attributes so that it has zero mean and variance of 1\n",
    "#https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35\n",
    "\n",
    "cols = data.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(data.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train=pd.DataFrame(sc_train, columns = cols)\n",
    "sc_test=pd.DataFrame(sc_test)\n",
    "sc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical features\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# extract categorical attributes from both training and test sets \n",
    "train_cat = data.select_dtypes(include=['object']).copy()\n",
    "test_cat = test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# encode the categorical attributes\n",
    "traincat = train_cat.apply(encoder.fit_transform)\n",
    "testcat = test_cat.apply(encoder.fit_transform)\n",
    "\n",
    "#drop the reduntant attribute class and append teh encoded categorical variables\n",
    "\n",
    "train_drop = traincat.drop(['class'], axis=1)\n",
    "a = traincat[['class']].copy()\n",
    "\n",
    "train_x=pd.concat([sc_train, train_drop], axis=1)\n",
    "train_y=data['class']\n",
    "test_x=pd.concat([sc_test, testcat],axis=1)\n",
    "traincat.head()\n",
    "test_x.shape\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(train_x, train_y);\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "features = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
    "features = features.sort_values('importance',ascending=False).set_index('feature')\n",
    "\n",
    "# plot features\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "features.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a RFE model\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=10)\n",
    "rfe = rfe.fit(train_x, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features\n",
    "\n",
    "#split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (train_x, train_y, train_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Train a  Model\n",
    "* Which ML model would you choose and why?\n",
    "* Train and evaluate the model using the train data\n",
    "* Is the data blanced? What are the implications, how can you deal with this?\n",
    "* Discuss the results -> possible improvements?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB \n",
    "\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "models=[]\n",
    "\n",
    "models.append(('NB Classifier', BNB))\n",
    "\n",
    "for i,v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    print('{} Model Evaluation'.format(i))\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Evaluate \n",
    "* report the F1-Score on the test data - Who will build the bes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating on the test data\n",
    "\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    print('{} Model Evaluation'.format(i))\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
